{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Session 4: Convolutional Neural Networks for Sequences\n",
        "## PyTorch CNNs for Genomics - Motif Detection and Feature Extraction\n",
        "\n",
        "**\ud83d\udcd6 Book References**: Deep Learning with PyTorch Ch. 8 (pages 245-290), Gen AI Ch. 4  \n",
        "**\u23f1\ufe0f Duration**: 3-4 hours  \n",
        "**\ud83c\udfaf Difficulty**: Intermediate\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83c\udfaf Learning Objectives & Core Functions\n",
        "\n",
        "### What You'll Learn:\n",
        "\u2705 1D convolutions for DNA/protein sequences  \n",
        "\u2705 Multi-kernel architectures for motif detection  \n",
        "\u2705 Pooling operations (max, average, global)  \n",
        "\u2705 Build DeepBind-style models  \n",
        "\u2705 Visualize learned filters as PWMs  \n",
        "\u2705 Extract sequence features automatically\n",
        "\n",
        "### Core PyTorch Functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nn.Conv1d(in_channels, out_channels, kernel_size)\n",
        "nn.MaxPool1d(kernel_size)\n",
        "nn.AvgPool1d(kernel_size)\n",
        "nn.AdaptiveMaxPool1d(output_size)\n",
        "nn.BatchNorm1d(num_features)\n",
        "F.conv1d()  # Functional interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83d\udcda Quick Theory\n",
        "\n",
        "### Why CNNs for Sequences?\n",
        "\n",
        "**DNA/Protein sequences have**:\n",
        "- Local patterns (motifs, binding sites)\n",
        "- Translation invariance (motifs can occur anywhere)\n",
        "- Hierarchical features (motifs \u2192 domains \u2192 functions)\n",
        "\n",
        "**CNNs provide**:\n",
        "- Parameter sharing across positions\n",
        "- Automatic feature learning\n",
        "- Much fewer parameters than fully connected\n",
        "\n",
        "### 1D Convolution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Sequence: ATCGATCG (one-hot encoded to 4xL)\n",
        "Kernel: 4x3 (4 channels, width 3)\n",
        "Output: Detections at each position"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83e\uddea Exercise 1: Basic 1D Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# One-hot encode DNA\n",
        "def one_hot_encode(seq):\n",
        "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "    encoding = np.zeros((4, len(seq)))\n",
        "    for i, base in enumerate(seq):\n",
        "        if base in mapping:\n",
        "            encoding[mapping[base], i] = 1\n",
        "    return torch.FloatTensor(encoding).unsqueeze(0)\n",
        "\n",
        "# Test sequence\n",
        "seq = \"ATCGATCG\" * 10\n",
        "X = one_hot_encode(seq)\n",
        "print(f\"Encoded shape: {X.shape}\")  # (1, 4, length)\n",
        "\n",
        "# Simple CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, kernel_size=8):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(4, 16, kernel_size)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "output = model(X)\n",
        "print(f\"Output shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83e\uddea Exercise 2: Motif Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data with known motif\n",
        "def generate_sequences_with_motif(n_samples=1000, seq_len=50, motif=\"TATAAA\"):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    \n",
        "    for _ in range(n_samples // 2):\n",
        "        # Positive: contains motif\n",
        "        pos = np.random.randint(0, seq_len - len(motif))\n",
        "        seq = list(np.random.choice(['A','C','G','T'], seq_len))\n",
        "        seq[pos:pos+len(motif)] = list(motif)\n",
        "        sequences.append(''.join(seq))\n",
        "        labels.append(1)\n",
        "        \n",
        "        # Negative: random\n",
        "        seq = ''.join(np.random.choice(['A','C','G','T'], seq_len))\n",
        "        sequences.append(seq)\n",
        "        labels.append(0)\n",
        "    \n",
        "    return sequences, labels\n",
        "\n",
        "sequences, labels = generate_sequences_with_motif()\n",
        "X = torch.stack([one_hot_encode(s).squeeze(0) for s in sequences])\n",
        "y = torch.FloatTensor(labels)\n",
        "\n",
        "print(f\"Data: {X.shape}, Labels: {y.shape}\")\n",
        "\n",
        "# CNN Motif Detector\n",
        "class MotifCNN(nn.Module):\n",
        "    def __init__(self, kernel_size=8, n_kernels=32):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(4, n_kernels, kernel_size)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc = nn.Linear(n_kernels, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv(x))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "model = MotifCNN()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X)\n",
        "    loss = criterion(predictions, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        acc = ((predictions > 0.5) == y).float().mean()\n",
        "        print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Acc={acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83e\uddea Exercise 3: Multi-Scale CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiScaleCNN(nn.Module):\n",
        "    def __init__(self, kernel_sizes=[6, 8, 10, 12]):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(4, 32, k) for k in kernel_sizes\n",
        "        ])\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc = nn.Linear(32 * len(kernel_sizes), 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv_outputs = []\n",
        "        for conv in self.convs:\n",
        "            out = F.relu(conv(x))\n",
        "            out = self.pool(out)\n",
        "            conv_outputs.append(out)\n",
        "        \n",
        "        x = torch.cat(conv_outputs, dim=1).squeeze(-1)\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "model = MultiScaleCNN()\n",
        "print(model)\n",
        "\n",
        "# Train similar to above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83e\uddea Exercise 4: Visualize Learned Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_conv_filters(model):\n",
        "    # Get first conv layer weights\n",
        "    weights = model.conv.weight.data\n",
        "    n_filters = weights.shape[0]\n",
        "    \n",
        "    fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < n_filters:\n",
        "            # Convert to PWM-like\n",
        "            filter_weights = weights[i].numpy()\n",
        "            ax.imshow(filter_weights, aspect='auto', cmap='RdBu_r')\n",
        "            ax.set_title(f'Filter {i+1}')\n",
        "            ax.set_yticks([0,1,2,3])\n",
        "            ax.set_yticklabels(['A','C','G','T'])\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "model = MotifCNN()\n",
        "# Train model first...\n",
        "visualize_conv_filters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83e\uddea Exercise 5: Splice Site Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# More complex task: predict splice sites\n",
        "class SpliceSiteCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(4, 64, kernel_size=11)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.conv2 = nn.Conv1d(64, 64, kernel_size=7)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(64, 32)\n",
        "        self.fc2 = nn.Linear(32, 3)  # 3 classes: donor, acceptor, neither\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SpliceSiteCNN()\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83c\udfaf Challenge: DeepBind Replication\n",
        "\n",
        "Build a model similar to DeepBind for TF binding prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DeepBindModel(nn.Module):\n",
        "    def __init__(self, seq_len=101, n_motifs=16, motif_len=24):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(4, n_motifs, motif_len)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=3, stride=3)\n",
        "        \n",
        "        # Calculate flattened size\n",
        "        conv_out_len = seq_len - motif_len + 1\n",
        "        pool_out_len = (conv_out_len - 3) // 3 + 1\n",
        "        flat_size = n_motifs * pool_out_len\n",
        "        \n",
        "        self.fc1 = nn.Linear(flat_size, 32)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "model = DeepBindModel()\n",
        "# Train on ChIP-seq data..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \u2705 Self-Assessment\n",
        "\n",
        "- [ ] Understand 1D convolution for sequences\n",
        "- [ ] Can explain kernel size vs receptive field\n",
        "- [ ] Know when to use pooling\n",
        "- [ ] Built multi-kernel architectures\n",
        "- [ ] Visualized learned filters\n",
        "- [ ] Applied to real genomics tasks\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udcdd Key Takeaways\n",
        "\n",
        "- **Conv1d**: Perfect for sequence data\n",
        "- **Multiple kernels**: Detect different patterns\n",
        "- **Pooling**: Downsample and aggregate\n",
        "- **Adaptive pooling**: Fixed output size\n",
        "- **Batch norm**: Faster, more stable training\n",
        "\n",
        "---\n",
        "\n",
        "*Session 4 Complete!*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}