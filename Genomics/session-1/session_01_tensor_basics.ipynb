{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 1: Tensor Basics and Operations\n",
    "## PyTorch for Genomics - Foundational Skills\n",
    "\n",
    "**Source**: Deep Learning with PyTorch (Second Edition), Chapter 3 - \"It starts with a tensor\"\n",
    "\n",
    "**Duration**: 2-3 hours  \n",
    "**Difficulty**: Beginner  \n",
    "**Prerequisites**: Basic Python, understanding of DNA/RNA basics\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this session, you will:\n",
    "1. Create and manipulate PyTorch tensors representing genomic data\n",
    "2. Understand tensor shapes, indexing, and slicing for sequence data\n",
    "3. Perform vectorized operations on genomic datasets\n",
    "4. Implement one-hot encoding for biological sequences\n",
    "5. Work with batched genomic data efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Theory Review\n",
    "\n",
    "### What are Tensors?\n",
    "Tensors are multi-dimensional arrays that can run on GPUs. In genomics:\n",
    "- **0D tensor (scalar)**: A single value (e.g., a gene expression measurement)\n",
    "- **1D tensor (vector)**: A sequence (e.g., expression levels across samples)\n",
    "- **2D tensor (matrix)**: Multiple sequences or expression matrix (genes √ó samples)\n",
    "- **3D tensor (batch)**: Multiple matrices (batch √ó genes √ó samples)\n",
    "\n",
    "### DNA Sequence Representation\n",
    "DNA sequences can be encoded as:\n",
    "1. **Integer encoding**: A=0, C=1, G=2, T=3\n",
    "2. **One-hot encoding**: Each nucleotide becomes a 4-element vector\n",
    "   - A = [1, 0, 0, 0]\n",
    "   - C = [0, 1, 0, 0]\n",
    "   - G = [0, 0, 1, 0]\n",
    "   - T = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Exercise 1: DNA Sequence Encoding\n",
    "\n",
    "### Part A: Basic Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Create a DNA sequence\n",
    "sequence = \"ATCGATCGTTAGC\"\n",
    "\n",
    "# Task 1.1: Create a mapping dictionary\n",
    "nucleotide_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "\n",
    "# Task 1.2: Convert sequence to integer tensor\n",
    "# YOUR CODE HERE\n",
    "encoded_seq = torch.tensor([nucleotide_to_int[n] for n in sequence])\n",
    "\n",
    "print(f\"Original sequence: {sequence}\")\n",
    "print(f\"Encoded tensor: {encoded_seq}\")\n",
    "print(f\"Tensor shape: {encoded_seq.shape}\")\n",
    "print(f\"Tensor dtype: {encoded_seq.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "Original sequence: ATCGATCGTTAGC\n",
    "Encoded tensor: tensor([0, 3, 1, 2, 0, 3, 1, 2, 3, 3, 0, 2, 1])\n",
    "Tensor shape: torch.Size([13])\n",
    "Tensor dtype: torch.int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence, nucleotide_to_int=None):\n",
    "    \"\"\"\n",
    "    Convert a DNA sequence to one-hot encoded tensor.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): DNA sequence string\n",
    "        nucleotide_to_int (dict): Mapping of nucleotides to integers\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: One-hot encoded tensor of shape (4, seq_length)\n",
    "    \"\"\"\n",
    "    if nucleotide_to_int is None:\n",
    "        nucleotide_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    \n",
    "    # Task 1.3: Implement one-hot encoding\n",
    "    # Hint: Use torch.zeros() and indexing\n",
    "    # YOUR CODE HERE\n",
    "    seq_length = len(sequence)\n",
    "    one_hot = torch.zeros(4, seq_length)\n",
    "    \n",
    "    for i, nucleotide in enumerate(sequence):\n",
    "        idx = nucleotide_to_int[nucleotide]\n",
    "        one_hot[idx, i] = 1\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "# Test your function\n",
    "seq = \"ATCG\"\n",
    "encoded = one_hot_encode(seq)\n",
    "print(f\"Sequence: {seq}\")\n",
    "print(f\"One-hot encoded:\\n{encoded}\")\n",
    "print(f\"Shape: {encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Vectorized One-Hot Encoding (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_vectorized(sequence):\n",
    "    \"\"\"\n",
    "    Faster vectorized one-hot encoding using PyTorch operations.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): DNA sequence string\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: One-hot encoded tensor of shape (4, seq_length)\n",
    "    \"\"\"\n",
    "    # Task 1.4: Implement using torch.nn.functional.one_hot\n",
    "    # YOUR CODE HERE\n",
    "    nucleotide_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    \n",
    "    # Convert to integer tensor\n",
    "    int_seq = torch.tensor([nucleotide_to_int[n] for n in sequence])\n",
    "    \n",
    "    # Use one_hot function\n",
    "    one_hot = torch.nn.functional.one_hot(int_seq, num_classes=4)\n",
    "    \n",
    "    # Transpose to get (4, seq_length) shape\n",
    "    return one_hot.T.float()\n",
    "\n",
    "# Test\n",
    "seq = \"ATCG\"\n",
    "encoded = one_hot_encode_vectorized(seq)\n",
    "print(f\"Vectorized one-hot:\\n{encoded}\")\n",
    "\n",
    "# Benchmark (optional)\n",
    "import time\n",
    "long_seq = \"ATCG\" * 1000\n",
    "\n",
    "start = time.time()\n",
    "_ = one_hot_encode(long_seq)\n",
    "time_loop = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "_ = one_hot_encode_vectorized(long_seq)\n",
    "time_vectorized = time.time() - start\n",
    "\n",
    "print(f\"\\nLoop version: {time_loop:.4f}s\")\n",
    "print(f\"Vectorized version: {time_vectorized:.4f}s\")\n",
    "print(f\"Speedup: {time_loop/time_vectorized:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Exercise 2: Gene Expression Matrix Operations\n",
    "\n",
    "Gene expression data is typically stored as a matrix where:\n",
    "- Rows = genes (e.g., 20,000 genes)\n",
    "- Columns = samples (e.g., 100 samples)\n",
    "\n",
    "### Part A: Creating and Exploring Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Simulate gene expression data\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "num_genes = 1000\n",
    "num_samples = 50\n",
    "\n",
    "# Task 2.1: Create random expression matrix\n",
    "# Use torch.randn for normally distributed data\n",
    "# YOUR CODE HERE\n",
    "expression_matrix = torch.randn(num_genes, num_samples)\n",
    "\n",
    "# Add some structure: make first 100 genes higher in first 25 samples\n",
    "expression_matrix[:100, :25] += 2.0\n",
    "\n",
    "print(f\"Expression matrix shape: {expression_matrix.shape}\")\n",
    "print(f\"Data type: {expression_matrix.dtype}\")\n",
    "print(f\"Mean expression: {expression_matrix.mean():.3f}\")\n",
    "print(f\"Std expression: {expression_matrix.std():.3f}\")\n",
    "print(f\"\\nFirst 5 genes, first 5 samples:\")\n",
    "print(expression_matrix[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_expression(expr_matrix, method='zscore'):\n",
    "    \"\"\"\n",
    "    Normalize gene expression matrix.\n",
    "    \n",
    "    Args:\n",
    "        expr_matrix (torch.Tensor): Expression matrix (genes √ó samples)\n",
    "        method (str): 'zscore' or 'minmax'\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Normalized expression matrix\n",
    "    \"\"\"\n",
    "    # Task 2.2: Implement z-score normalization (per gene)\n",
    "    # Formula: (x - mean) / std\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    if method == 'zscore':\n",
    "        # Normalize each gene (row) independently\n",
    "        mean = expr_matrix.mean(dim=1, keepdim=True)\n",
    "        std = expr_matrix.std(dim=1, keepdim=True)\n",
    "        normalized = (expr_matrix - mean) / (std + 1e-8)  # Add epsilon to avoid division by zero\n",
    "        \n",
    "    elif method == 'minmax':\n",
    "        # Task 2.3: Implement min-max normalization\n",
    "        # Formula: (x - min) / (max - min)\n",
    "        # YOUR CODE HERE\n",
    "        min_val = expr_matrix.min(dim=1, keepdim=True)[0]\n",
    "        max_val = expr_matrix.max(dim=1, keepdim=True)[0]\n",
    "        normalized = (expr_matrix - min_val) / (max_val - min_val + 1e-8)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization method: {method}\")\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# Test normalization\n",
    "normalized_zscore = normalize_expression(expression_matrix, method='zscore')\n",
    "normalized_minmax = normalize_expression(expression_matrix, method='minmax')\n",
    "\n",
    "print(\"Z-score normalized:\")\n",
    "print(f\"  Mean: {normalized_zscore.mean():.6f}\")\n",
    "print(f\"  Std: {normalized_zscore.std():.6f}\")\n",
    "\n",
    "print(\"\\nMin-max normalized:\")\n",
    "print(f\"  Min: {normalized_minmax.min():.6f}\")\n",
    "print(f\"  Max: {normalized_minmax.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.4: Calculate various statistics\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Per-gene statistics\n",
    "gene_means = expression_matrix.mean(dim=1)  # Mean across samples\n",
    "gene_stds = expression_matrix.std(dim=1)    # Std across samples\n",
    "\n",
    "# Per-sample statistics  \n",
    "sample_means = expression_matrix.mean(dim=0)  # Mean across genes\n",
    "sample_stds = expression_matrix.std(dim=0)    # Std across genes\n",
    "\n",
    "print(\"Per-gene statistics:\")\n",
    "print(f\"  Mean of gene means: {gene_means.mean():.3f}\")\n",
    "print(f\"  Mean of gene stds: {gene_stds.mean():.3f}\")\n",
    "\n",
    "print(\"\\nPer-sample statistics:\")\n",
    "print(f\"  Mean of sample means: {sample_means.mean():.3f}\")\n",
    "print(f\"  Mean of sample stds: {sample_stds.mean():.3f}\")\n",
    "\n",
    "# Find differentially expressed genes (simple approach)\n",
    "group1_mean = expression_matrix[:, :25].mean(dim=1)\n",
    "group2_mean = expression_matrix[:, 25:].mean(dim=1)\n",
    "fold_change = group1_mean - group2_mean\n",
    "\n",
    "# Get top 10 upregulated genes\n",
    "top_genes_idx = torch.topk(fold_change, k=10).indices\n",
    "print(f\"\\nTop 10 upregulated gene indices: {top_genes_idx}\")\n",
    "print(f\"Their fold changes: {fold_change[top_genes_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Exercise 3: K-mer Analysis\n",
    "\n",
    "K-mers are subsequences of length k from a biological sequence.\n",
    "\n",
    "### Part A: Extract K-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kmers(sequence, k=6, step=1):\n",
    "    \"\"\"\n",
    "    Extract k-mers from a DNA sequence.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): DNA sequence\n",
    "        k (int): K-mer length\n",
    "        step (int): Step size (1 for overlapping k-mers)\n",
    "        \n",
    "    Returns:\n",
    "        list: List of k-mer strings\n",
    "    \"\"\"\n",
    "    # Task 3.1: Extract k-mers\n",
    "    # YOUR CODE HERE\n",
    "    kmers = []\n",
    "    for i in range(0, len(sequence) - k + 1, step):\n",
    "        kmer = sequence[i:i+k]\n",
    "        kmers.append(kmer)\n",
    "    return kmers\n",
    "\n",
    "# Test\n",
    "sequence = \"ATCGATCGTTAGC\"\n",
    "kmers = extract_kmers(sequence, k=6, step=1)\n",
    "print(f\"Sequence: {sequence}\")\n",
    "print(f\"6-mers (overlapping): {kmers}\")\n",
    "print(f\"Number of 6-mers: {len(kmers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: K-mer Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_kmer_frequencies(sequence, k=3):\n",
    "    \"\"\"\n",
    "    Count frequencies of all k-mers in a sequence.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): DNA sequence\n",
    "        k (int): K-mer length\n",
    "        \n",
    "    Returns:\n",
    "        dict: K-mer frequencies\n",
    "    \"\"\"\n",
    "    # Task 3.2: Count k-mer frequencies\n",
    "    # YOUR CODE HERE\n",
    "    kmers = extract_kmers(sequence, k=k)\n",
    "    frequencies = {}\n",
    "    \n",
    "    for kmer in kmers:\n",
    "        frequencies[kmer] = frequencies.get(kmer, 0) + 1\n",
    "    \n",
    "    return frequencies\n",
    "\n",
    "# Test\n",
    "sequence = \"ATCGATCGATCG\"\n",
    "freq = count_kmer_frequencies(sequence, k=3)\n",
    "print(f\"3-mer frequencies:\")\n",
    "for kmer, count in sorted(freq.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {kmer}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Batch K-mer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_kmer_batch(kmers):\n",
    "    \"\"\"\n",
    "    Encode a batch of k-mers as one-hot tensors.\n",
    "    \n",
    "    Args:\n",
    "        kmers (list): List of k-mer strings (all same length)\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Batch tensor of shape (batch_size, 4, k)\n",
    "    \"\"\"\n",
    "    # Task 3.3: Encode batch of k-mers\n",
    "    # YOUR CODE HERE\n",
    "    nucleotide_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    \n",
    "    batch_size = len(kmers)\n",
    "    k = len(kmers[0])\n",
    "    \n",
    "    # Create batch tensor\n",
    "    batch = torch.zeros(batch_size, 4, k)\n",
    "    \n",
    "    for i, kmer in enumerate(kmers):\n",
    "        for j, nucleotide in enumerate(kmer):\n",
    "            idx = nucleotide_to_int[nucleotide]\n",
    "            batch[i, idx, j] = 1\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Test\n",
    "kmers = [\"ATCGAT\", \"GCTAGC\", \"TTAGCC\"]\n",
    "batch = encode_kmer_batch(kmers)\n",
    "print(f\"Batch shape: {batch.shape}\")\n",
    "print(f\"First k-mer encoding:\\n{batch[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Exercise 4: Position Weight Matrix (PWM)\n",
    "\n",
    "PWMs are used to represent sequence motifs.\n",
    "\n",
    "### Part A: Create PWM from Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pwm(sequences):\n",
    "    \"\"\"\n",
    "    Create a position weight matrix from aligned sequences.\n",
    "    \n",
    "    Args:\n",
    "        sequences (list): List of aligned sequences (same length)\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: PWM of shape (4, motif_length)\n",
    "    \"\"\"\n",
    "    # Task 4.1: Create PWM\n",
    "    # YOUR CODE HERE\n",
    "    nucleotide_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    \n",
    "    motif_length = len(sequences[0])\n",
    "    pwm = torch.zeros(4, motif_length)\n",
    "    \n",
    "    # Count nucleotides at each position\n",
    "    for seq in sequences:\n",
    "        for pos, nucleotide in enumerate(seq):\n",
    "            idx = nucleotide_to_int[nucleotide]\n",
    "            pwm[idx, pos] += 1\n",
    "    \n",
    "    # Convert counts to frequencies\n",
    "    pwm = pwm / len(sequences)\n",
    "    \n",
    "    return pwm\n",
    "\n",
    "# Test\n",
    "motif_sequences = [\n",
    "    \"ATCGAT\",\n",
    "    \"ATCGAT\",\n",
    "    \"ATGGAT\",\n",
    "    \"ATCGAA\",\n",
    "    \"ATCGAT\",\n",
    "]\n",
    "\n",
    "pwm = create_pwm(motif_sequences)\n",
    "print(\"Position Weight Matrix:\")\n",
    "print(\"    Pos: 0     1     2     3     4     5\")\n",
    "nucleotides = ['A', 'C', 'G', 'T']\n",
    "for i, nuc in enumerate(nucleotides):\n",
    "    values = ' '.join([f\"{pwm[i, j]:.2f}\" for j in range(pwm.shape[1])])\n",
    "    print(f\"{nuc}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Score Sequence with PWM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_with_pwm(sequence, pwm):\n",
    "    \"\"\"\n",
    "    Score a sequence using a PWM.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): DNA sequence to score\n",
    "        pwm (torch.Tensor): PWM of shape (4, motif_length)\n",
    "        \n",
    "    Returns:\n",
    "        float: Log-likelihood score\n",
    "    \"\"\"\n",
    "    # Task 4.2: Score sequence\n",
    "    # YOUR CODE HERE\n",
    "    nucleotide_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    \n",
    "    if len(sequence) != pwm.shape[1]:\n",
    "        raise ValueError(\"Sequence length must match PWM width\")\n",
    "    \n",
    "    score = 0.0\n",
    "    for pos, nucleotide in enumerate(sequence):\n",
    "        idx = nucleotide_to_int[nucleotide]\n",
    "        # Log-likelihood score (add pseudocount to avoid log(0))\n",
    "        prob = pwm[idx, pos] + 1e-8\n",
    "        score += torch.log2(prob).item()\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Test scoring\n",
    "test_sequences = [\n",
    "    \"ATCGAT\",  # Perfect match\n",
    "    \"ATGGAT\",  # One mismatch\n",
    "    \"GGGGGG\",  # Complete mismatch\n",
    "]\n",
    "\n",
    "print(\"Sequence scores:\")\n",
    "for seq in test_sequences:\n",
    "    score = score_with_pwm(seq, pwm)\n",
    "    print(f\"  {seq}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Scan Sequence for Motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_sequence(sequence, pwm, threshold=-10.0):\n",
    "    \"\"\"\n",
    "    Scan a long sequence for motif occurrences.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): Long DNA sequence to scan\n",
    "        pwm (torch.Tensor): PWM of shape (4, motif_length)\n",
    "        threshold (float): Minimum score for a hit\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (position, score) tuples for hits\n",
    "    \"\"\"\n",
    "    # Task 4.3: Scan sequence and find high-scoring positions\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    motif_length = pwm.shape[1]\n",
    "    hits = []\n",
    "    \n",
    "    for i in range(len(sequence) - motif_length + 1):\n",
    "        subseq = sequence[i:i+motif_length]\n",
    "        score = score_with_pwm(subseq, pwm)\n",
    "        \n",
    "        if score >= threshold:\n",
    "            hits.append((i, score))\n",
    "    \n",
    "    return hits\n",
    "\n",
    "# Test scanning\n",
    "long_sequence = \"GGGG\" + \"ATCGAT\" + \"AAAA\" + \"ATGGAT\" + \"TTTT\" + \"ATCGAT\" + \"CCCC\"\n",
    "hits = scan_sequence(long_sequence, pwm, threshold=-5.0)\n",
    "\n",
    "print(f\"Scanning sequence of length {len(long_sequence)}\")\n",
    "print(f\"Found {len(hits)} hits:\")\n",
    "for pos, score in hits:\n",
    "    subseq = long_sequence[pos:pos+6]\n",
    "    print(f\"  Position {pos}: {subseq} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Exercise 5: Broadcasting and Batch Operations\n",
    "\n",
    "Understanding broadcasting is crucial for efficient genomics computations.\n",
    "\n",
    "### Part A: Broadcasting Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Task 5.1: Understand broadcasting with expression data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create expression matrix\n",
    "expression = torch.randn(100, 20)  # 100 genes, 20 samples\n",
    "\n",
    "# Calculate per-gene mean\n",
    "gene_means = expression.mean(dim=1, keepdim=True)  # Shape: (100, 1)\n",
    "\n",
    "# Center data (subtract mean from each sample)\n",
    "centered = expression - gene_means  # Broadcasting!\n",
    "\n",
    "print(f\"Expression shape: {expression.shape}\")\n",
    "print(f\"Gene means shape: {gene_means.shape}\")\n",
    "print(f\"Centered shape: {centered.shape}\")\n",
    "print(f\"\\nVerify centering (means should be ~0):\")\n",
    "print(f\"Centered gene means: {centered.mean(dim=1)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Batch Distance Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairwise_distances(sequences_tensor):\n",
    "    \"\"\"\n",
    "    Calculate pairwise Hamming distances between sequences.\n",
    "    \n",
    "    Args:\n",
    "        sequences_tensor (torch.Tensor): Shape (num_sequences, 4, seq_length)\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Distance matrix of shape (num_sequences, num_sequences)\n",
    "    \"\"\"\n",
    "    # Task 5.2: Implement using broadcasting\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    num_seqs = sequences_tensor.shape[0]\n",
    "    \n",
    "    # Expand dimensions for broadcasting\n",
    "    # Shape: (num_seqs, 1, 4, seq_length)\n",
    "    seq_a = sequences_tensor.unsqueeze(1)\n",
    "    \n",
    "    # Shape: (1, num_seqs, 4, seq_length)\n",
    "    seq_b = sequences_tensor.unsqueeze(0)\n",
    "    \n",
    "    # Calculate element-wise differences and sum\n",
    "    # Hamming distance = number of positions where sequences differ\n",
    "    differences = (seq_a != seq_b).float()\n",
    "    distances = differences.sum(dim=(2, 3))\n",
    "    \n",
    "    return distances\n",
    "\n",
    "# Test with k-mers\n",
    "kmers = [\"ATCGAT\", \"ATCGAA\", \"GGGGGG\", \"ATCGAT\"]\n",
    "batch = encode_kmer_batch(kmers)\n",
    "\n",
    "distances = calculate_pairwise_distances(batch)\n",
    "print(\"Pairwise distances:\")\n",
    "print(distances)\n",
    "print(f\"\\nExpected: identical sequences have distance 0\")\n",
    "print(f\"Sequences 0 and 3 are identical: distance = {distances[0, 3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Challenge Problems\n",
    "\n",
    "### Challenge 1: Efficient Codon Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_protein(dna_sequence):\n",
    "    \"\"\"\n",
    "    Translate DNA sequence to protein sequence.\n",
    "    \n",
    "    Args:\n",
    "        dna_sequence (str): DNA sequence (length must be multiple of 3)\n",
    "        \n",
    "    Returns:\n",
    "        str: Protein sequence (single letter amino acid codes)\n",
    "    \"\"\"\n",
    "    # Task: Implement codon translation\n",
    "    # Hint: Create a codon table dictionary\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    codon_table = {\n",
    "        'TTT': 'F', 'TTC': 'F', 'TTA': 'L', 'TTG': 'L',\n",
    "        'TCT': 'S', 'TCC': 'S', 'TCA': 'S', 'TCG': 'S',\n",
    "        'TAT': 'Y', 'TAC': 'Y', 'TAA': '*', 'TAG': '*',\n",
    "        'TGT': 'C', 'TGC': 'C', 'TGA': '*', 'TGG': 'W',\n",
    "        'CTT': 'L', 'CTC': 'L', 'CTA': 'L', 'CTG': 'L',\n",
    "        'CCT': 'P', 'CCC': 'P', 'CCA': 'P', 'CCG': 'P',\n",
    "        'CAT': 'H', 'CAC': 'H', 'CAA': 'Q', 'CAG': 'Q',\n",
    "        'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R',\n",
    "        'ATT': 'I', 'ATC': 'I', 'ATA': 'I', 'ATG': 'M',\n",
    "        'ACT': 'T', 'ACC': 'T', 'ACA': 'T', 'ACG': 'T',\n",
    "        'AAT': 'N', 'AAC': 'N', 'AAA': 'K', 'AAG': 'K',\n",
    "        'AGT': 'S', 'AGC': 'S', 'AGA': 'R', 'AGG': 'R',\n",
    "        'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V',\n",
    "        'GCT': 'A', 'GCC': 'A', 'GCA': 'A', 'GCG': 'A',\n",
    "        'GAT': 'D', 'GAC': 'D', 'GAA': 'E', 'GAG': 'E',\n",
    "        'GGT': 'G', 'GGC': 'G', 'GGA': 'G', 'GGG': 'G',\n",
    "    }\n",
    "    \n",
    "    if len(dna_sequence) % 3 != 0:\n",
    "        raise ValueError(\"DNA sequence length must be multiple of 3\")\n",
    "    \n",
    "    protein = []\n",
    "    for i in range(0, len(dna_sequence), 3):\n",
    "        codon = dna_sequence[i:i+3]\n",
    "        amino_acid = codon_table.get(codon, 'X')  # X for unknown\n",
    "        protein.append(amino_acid)\n",
    "        if amino_acid == '*':  # Stop codon\n",
    "            break\n",
    "    \n",
    "    return ''.join(protein)\n",
    "\n",
    "# Test\n",
    "dna = \"ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG\"\n",
    "protein = translate_to_protein(dna)\n",
    "print(f\"DNA:     {dna}\")\n",
    "print(f\"Protein: {protein}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: GC Content Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gc_content(sequence, window_size=100, step=50):\n",
    "    \"\"\"\n",
    "    Calculate GC content in sliding windows.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): DNA sequence\n",
    "        window_size (int): Window size\n",
    "        step (int): Step size\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: GC content values for each window\n",
    "    \"\"\"\n",
    "    # Task: Calculate GC percentage in windows\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    gc_values = []\n",
    "    \n",
    "    for i in range(0, len(sequence) - window_size + 1, step):\n",
    "        window = sequence[i:i+window_size]\n",
    "        gc_count = window.count('G') + window.count('C')\n",
    "        gc_percent = 100.0 * gc_count / window_size\n",
    "        gc_values.append(gc_percent)\n",
    "    \n",
    "    return torch.tensor(gc_values)\n",
    "\n",
    "# Test\n",
    "long_seq = \"AT\" * 50 + \"GC\" * 50 + \"AT\" * 50  # Variable GC content\n",
    "gc_content = analyze_gc_content(long_seq, window_size=50, step=25)\n",
    "\n",
    "print(f\"Sequence length: {len(long_seq)}\")\n",
    "print(f\"Number of windows: {len(gc_content)}\")\n",
    "print(f\"GC content per window:\")\n",
    "print(gc_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Self-Assessment\n",
    "\n",
    "Before moving to Session 2, ensure you can:\n",
    "\n",
    "- [ ] Create tensors from genomic sequences\n",
    "- [ ] Implement one-hot encoding efficiently\n",
    "- [ ] Perform normalization on expression matrices\n",
    "- [ ] Calculate statistics using tensor operations\n",
    "- [ ] Understand and use tensor broadcasting\n",
    "- [ ] Work with batched sequence data\n",
    "- [ ] Implement PWM creation and scoring\n",
    "- [ ] Extract and encode k-mers from sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Additional Practice Ideas\n",
    "\n",
    "1. **Load real data**: Download a FASTA file and process it with PyTorch\n",
    "2. **Visualize PWMs**: Use matplotlib to create sequence logos\n",
    "3. **Benchmark operations**: Compare NumPy vs PyTorch for genomic operations\n",
    "4. **Add ambiguous bases**: Extend encoding to handle N (any base)\n",
    "5. **RNA analysis**: Modify functions to work with RNA sequences (U instead of T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Once you're comfortable with these exercises, move on to:\n",
    "- **Session 2**: Autograd and gradient descent for genomics models\n",
    "- Try implementing these functions with GPU acceleration using `.to('cuda')`\n",
    "- Explore PyTorch's `torch.utils.data.Dataset` for loading large genomic files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "- PyTorch Tensor Documentation: https://pytorch.org/docs/stable/tensors.html\n",
    "- NumPy to PyTorch: https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
    "- Biopython for sequence handling: https://biopython.org/\n",
    "\n",
    "Good luck with your practice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
